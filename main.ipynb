{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "705be40e",
   "metadata": {},
   "source": [
    "# ## IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9285da91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2  # Import OpenCV for image processing\n",
    "import mediapipe as mp  # Import MediaPipe for hand tracking\n",
    "import pyautogui  # Import PyAutoGUI for GUI automation\n",
    "import random  # Import random for generating random numbers\n",
    "import util  # Import custom utility functions\n",
    "from pynput.mouse import Button, Controller  # Import mouse control from pynput"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d618e2b3",
   "metadata": {},
   "source": [
    "# ## Mouse Controller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "bf8a69cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mouse controller instance\n",
    "mouse = Controller()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c757341e",
   "metadata": {},
   "source": [
    "# ## Screen Dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c244533f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the screen width and height\n",
    "screen_width, screen_height = pyautogui.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1eaa84c",
   "metadata": {},
   "source": [
    "# ## MediaPipe Hands Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a29f0c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize MediaPipe Hands module\n",
    "mpHands = mp.solutions.hands\n",
    "hands = mpHands.Hands(\n",
    "    static_image_mode=False,  # Set to False for real-time detection\n",
    "    model_complexity=1,  # Set model complexity (0 or 1)\n",
    "    min_detection_confidence=0.7,  # Minimum confidence for detection\n",
    "    min_tracking_confidence=0.7,  # Minimum confidence for tracking\n",
    "    max_num_hands=1  # Maximum number of hands to track\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4fd4551",
   "metadata": {},
   "source": [
    "# ## Function Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a2d53377",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Find Finger Tip\n",
    "# Function to find the tip of the index finger\n",
    "def find_finger_tip(processed):\n",
    "    if processed.multi_hand_landmarks:  # Check if hand landmarks are detected\n",
    "        hand_landmarks = processed.multi_hand_landmarks[0]  # Get the first hand's landmarks\n",
    "        return hand_landmarks.landmark[mpHands.HandLandmark.INDEX_FINGER_TIP]  # Return index finger tip landmark\n",
    "    return None  # Return None if no hand is detected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6569259b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Move Mouse\n",
    "# Function to move the mouse to the position of the index finger tip\n",
    "def move_mouse(index_finger_tip):\n",
    "    if index_finger_tip is not None:  # Check if the finger tip is detected\n",
    "        x = int(index_finger_tip.x * screen_width)  # Calculate x position\n",
    "        y = int(index_finger_tip.y * screen_height)  # Calculate y position\n",
    "        pyautogui.moveTo(x, y)  # Move the mouse to the calculated position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "aa68c105",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Gesture Detection Functions\n",
    "# Function to determine if a left click gesture is made\n",
    "def is_left_click(landmarks_list, thumb_index_dist):\n",
    "    return (util.get_angle(landmarks_list[5], landmarks_list[6], landmarks_list[8]) < 50 and\n",
    "            util.get_distance([landmarks_list[9], landmarks_list[10], landmarks_list[12]]) > 90 and\n",
    "            util.get_angle(landmarks_list[13], landmarks_list[14], landmarks_list[16]) > 90 and  # Ring finger up\n",
    "            thumb_index_dist > 50)\n",
    "\n",
    "# Function to determine if a right click gesture is made\n",
    "def is_right_click(landmarks_list, thumb_index_dist):\n",
    "    return (util.get_angle(landmarks_list[9], landmarks_list[10], landmarks_list[12]) < 50 and\n",
    "            util.get_distance([landmarks_list[5], landmarks_list[6], landmarks_list[8]]) > 90 and\n",
    "            thumb_index_dist > 50)\n",
    "\n",
    "# Function to determine if a double click gesture is made\n",
    "def is_double_click(landmarks_list, thumb_index_dist):\n",
    "    return (util.get_angle(landmarks_list[5], landmarks_list[6], landmarks_list[8]) < 50 and\n",
    "            util.get_distance([landmarks_list[9], landmarks_list[10], landmarks_list[12]]) < 50 and\n",
    "            thumb_index_dist > 50)\n",
    "\n",
    "# Function to determine if a screenshot gesture is made\n",
    "def is_screenshot(landmarks_list, thumb_index_dist):\n",
    "    return (util.get_angle(landmarks_list[5], landmarks_list[6], landmarks_list[8]) < 50 and\n",
    "            util.get_distance([landmarks_list[9], landmarks_list[10], landmarks_list[12]]) < 50 and\n",
    "            thumb_index_dist < 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "facba3fa",
   "metadata": {},
   "source": [
    "# ### Detect Gestures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c7ec1d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to detect gestures based on hand landmarks\n",
    "def detect_gestures(frame, landmarks_list, processed):\n",
    "    if len(landmarks_list) >= 21:  # Check if enough landmarks are detected\n",
    "        index_finger_tip = find_finger_tip(processed)  # Find the index finger tip\n",
    "        thumb_index_distance = util.get_distance([landmarks_list[4], landmarks_list[5]])  # Calculate distance between thumb and index finger\n",
    "\n",
    "        # Move mouse if thumb and index finger are close and index finger is raised\n",
    "        if thumb_index_distance < 50 and util.get_angle(landmarks_list[5], landmarks_list[6], landmarks_list[8]) > 90:\n",
    "            move_mouse(index_finger_tip)\n",
    "\n",
    "        # LEFT CLICK\n",
    "        elif is_left_click(landmarks_list, thumb_index_distance):\n",
    "            mouse.press(Button.left)  # Press left mouse button\n",
    "            mouse.release(Button.left)  # Release left mouse button\n",
    "            cv2.putText(frame, \"Left Click\", (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)  # Display text on frame\n",
    "\n",
    "        # RIGHT CLICK\n",
    "        elif is_right_click(landmarks_list, thumb_index_distance):\n",
    "            mouse.press(Button.right)  # Press right mouse button\n",
    "            mouse.release(Button.right)  # Release right mouse button\n",
    "            cv2.putText(frame, \"Right Click\", (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)  # Display text on frame\n",
    "\n",
    "        # DOUBLE CLICK\n",
    "        elif is_double_click(landmarks_list, thumb_index_distance):\n",
    "            pyautogui.doubleClick()  # Perform double click\n",
    "            cv2.putText(frame, \"Double Click\", (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 0), 2)  # Display text on frame\n",
    "\n",
    "        # SCREENSHOT\n",
    "        elif is_screenshot(landmarks_list, thumb_index_distance):\n",
    "            iml = pyautogui.screenshot()  # Take a screenshot\n",
    "            label = random.randint(1, 1000)  # Generate a random label for the screenshot\n",
    "            iml.save(f'my_screenshot_{label}.png')  # Save the screenshot with the label\n",
    "            cv2.putText(frame, \"Screenshot Taken\", (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 0), 2)  # Display text on frame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a7ba10e",
   "metadata": {},
   "source": [
    "# ## Main Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ad58c67c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main function to run the application\n",
    "def main():\n",
    "    cap = cv2.VideoCapture(0)  # Start video capture from the webcam\n",
    "    draw = mp.solutions.drawing_utils  # Initialize drawing utilities for MediaPipe\n",
    "\n",
    "    try:\n",
    "        while cap.isOpened():  # Loop until the webcam is opened\n",
    "            ret, frame = cap.read()  # Read a frame from the webcam\n",
    "\n",
    "            if not ret:  # Break the loop if no frame is captured\n",
    "                break\n",
    "            frame = cv2.flip(frame, 1)  # Flip the frame horizontally\n",
    "            frameRGB = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)  # Convert frame to RGB\n",
    "            processed = hands.process(frameRGB)  # Process the frame for hand landmarks\n",
    "\n",
    "            landmarks_list = []  # Initialize list to store landmarks\n",
    "\n",
    "            if processed.multi_hand_landmarks:  # Check if hand landmarks are detected\n",
    "                hand_landmarks = processed.multi_hand_landmarks[0]  # Get the first hand's landmarks\n",
    "                draw.draw_landmarks(frame, hand_landmarks, mpHands.HAND_CONNECTIONS)  # Draw landmarks on the frame\n",
    "\n",
    "                for lm in hand_landmarks.landmark:  # Loop through each landmark\n",
    "                    landmarks_list.append((lm.x, lm.y))  # Append landmark coordinates to the list\n",
    "\n",
    "            detect_gestures(frame, landmarks_list, processed)  # Detect gestures based on landmarks\n",
    "\n",
    "            cv2.imshow('Frame', frame)  # Display the frame with landmarks\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):  # Exit if 'q' is pressed\n",
    "                break\n",
    "\n",
    "    finally:\n",
    "        cap.release()  # Release the webcam\n",
    "        cv2.destroyAllWindows()  # Close all OpenCV windows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f41db24",
   "metadata": {},
   "source": [
    "# ## Entry Point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "23585f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entry point of the program\n",
    "if __name__ == \"__main__\":\n",
    "    main()  # Call the main function to run the application"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
